{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1+cu101'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = os.path.join(data_path, 'train')\n",
    "test_image_path = os.path.join(data_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_paths = glob.glob(os.path.join(data_path, 'train', '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>has_cactus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000d1e9a533f62e55c289303b072733d.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011485b40695e9138e92d0b3fb55128.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0014d7a11e90b62848904c1418fc8cf2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  has_cactus\n",
       "0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n",
       "1  000c8a36845c0208e833c79c1bffedd1.jpg           1\n",
       "2  000d1e9a533f62e55c289303b072733d.jpg           1\n",
       "3  0011485b40695e9138e92d0b3fb55128.jpg           1\n",
       "4  0014d7a11e90b62848904c1418fc8cf2.jpg           1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,10, figsize=(15, 6))\n",
    "r = 0\n",
    "c = 0\n",
    "for idx in train_table.index[:30]:\n",
    "    arr_img = np.array(Image.open(os.path.join(data_path, \"train\", train_table.loc[idx, \"id\"])))\n",
    "    ax[r, c].imshow(arr_img)\n",
    "    ax[r, c].set_title(\"has_cactus: \" + str(train_table.loc[idx, \"has_cactus\"]))\n",
    "    ax[r, c].axis(\"off\")\n",
    "    c += 1\n",
    "    if c % 10 == 0:\n",
    "        c = 0\n",
    "        r += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(img):\n",
    "    img = Image.open(img)\n",
    "#     img_grey = img.convert('L')\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = preprocessing(os.path.join(train_image_path, train_table.loc[1, \"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(im).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table = train_table.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_table[\"id\"].values, train_table[\"has_cactus\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([ 3504, 10496]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([ 860, 2640]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CactusDataset(Dataset):\n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        self.dataset = {\n",
    "            \"train\": (X_train, y_train, len(y_train)),\n",
    "            \"test\": (X_test, y_test, len(y_test))\n",
    "        }\n",
    "        self.set_split(split=\"train\")\n",
    "        \n",
    "    def set_split(self, split=\"train\"):\n",
    "        self.data_x, self.data_y, self.length = self.dataset[split]\n",
    "    \n",
    "    def preprocessing(self, filename):\n",
    "        path = os.path.join(train_image_path, filename)\n",
    "        img = Image.open(path)\n",
    "            \n",
    "        im_arr = np.array(img) / 255\n",
    "        im_arr = im_arr.transpose(2,0,1)\n",
    "        \n",
    "        return im_arr\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.Tensor(self.preprocessing(self.data_x[idx]))\n",
    "        y = torch.Tensor([self.data_y[idx]])\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 128, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 1, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(484, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        out = self.network(input_)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CactusDataset(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 907,046\n"
     ]
    }
   ],
   "source": [
    "## sum weight + bias\n",
    "num_param = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {num_param:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y, out):\n",
    "    out_indicies = (out > 0.5).long()\n",
    "    y = y.long()\n",
    "    n_correct = torch.eq(y, out_indicies).sum().item()\n",
    "    accuracy = n_correct / y.shape[0]\n",
    "    \n",
    "    return accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = DataLoader(dataset, batch_size = 2)\n",
    "for data in data_sample:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "\ttrain loss: 0.63 | accuracy: 74.94\n",
      "\tval loss: 0.56 | accuracy: 76.15\n",
      "epoch: 2\n",
      "\ttrain loss: 0.58 | accuracy: 74.94\n",
      "\tval loss: 0.56 | accuracy: 76.15\n",
      "epoch: 3\n",
      "\ttrain loss: 0.57 | accuracy: 75.00\n",
      "\tval loss: 0.55 | accuracy: 76.15\n",
      "epoch: 4\n",
      "\ttrain loss: 0.55 | accuracy: 74.91\n",
      "\tval loss: 0.53 | accuracy: 76.15\n",
      "epoch: 5\n",
      "\ttrain loss: 0.53 | accuracy: 74.97\n",
      "\tval loss: 0.49 | accuracy: 76.15\n",
      "epoch: 6\n",
      "\ttrain loss: 0.47 | accuracy: 74.98\n",
      "\tval loss: 0.41 | accuracy: 76.15\n",
      "epoch: 7\n",
      "\ttrain loss: 0.39 | accuracy: 75.11\n",
      "\tval loss: 0.35 | accuracy: 76.41\n",
      "epoch: 8\n",
      "\ttrain loss: 0.35 | accuracy: 75.69\n",
      "\tval loss: 0.32 | accuracy: 76.86\n",
      "epoch: 9\n",
      "\ttrain loss: 0.33 | accuracy: 75.85\n",
      "\tval loss: 0.31 | accuracy: 76.86\n",
      "epoch: 10\n",
      "\ttrain loss: 0.32 | accuracy: 75.87\n",
      "\tval loss: 0.31 | accuracy: 76.93\n",
      "epoch: 11\n",
      "\ttrain loss: 0.32 | accuracy: 76.08\n",
      "\tval loss: 0.31 | accuracy: 77.02\n",
      "epoch: 12\n",
      "\ttrain loss: 0.31 | accuracy: 76.11\n",
      "\tval loss: 0.30 | accuracy: 77.18\n",
      "epoch: 13\n",
      "\ttrain loss: 0.31 | accuracy: 76.09\n",
      "\tval loss: 0.29 | accuracy: 77.11\n",
      "epoch: 14\n",
      "\ttrain loss: 0.30 | accuracy: 76.12\n",
      "\tval loss: 0.30 | accuracy: 77.22\n",
      "epoch: 15\n",
      "\ttrain loss: 0.31 | accuracy: 76.07\n",
      "\tval loss: 0.29 | accuracy: 77.60\n",
      "epoch: 16\n",
      "\ttrain loss: 0.30 | accuracy: 76.43\n",
      "\tval loss: 0.28 | accuracy: 77.69\n",
      "epoch: 17\n",
      "\ttrain loss: 0.29 | accuracy: 76.41\n",
      "\tval loss: 0.28 | accuracy: 77.67\n",
      "epoch: 18\n",
      "\ttrain loss: 0.28 | accuracy: 76.42\n",
      "\tval loss: 0.28 | accuracy: 77.34\n",
      "epoch: 19\n",
      "\ttrain loss: 0.29 | accuracy: 76.34\n",
      "\tval loss: 0.27 | accuracy: 77.86\n",
      "epoch: 20\n",
      "\ttrain loss: 0.28 | accuracy: 76.53\n",
      "\tval loss: 0.26 | accuracy: 77.76\n",
      "epoch: 21\n",
      "\ttrain loss: 0.28 | accuracy: 76.63\n",
      "\tval loss: 0.26 | accuracy: 77.62\n",
      "epoch: 22\n",
      "\ttrain loss: 0.27 | accuracy: 76.88\n",
      "\tval loss: 0.26 | accuracy: 77.70\n",
      "epoch: 23\n",
      "\ttrain loss: 0.27 | accuracy: 76.85\n",
      "\tval loss: 0.25 | accuracy: 77.93\n",
      "epoch: 24\n",
      "\ttrain loss: 0.27 | accuracy: 76.81\n",
      "\tval loss: 0.26 | accuracy: 78.00\n",
      "epoch: 25\n",
      "\ttrain loss: 0.26 | accuracy: 77.07\n",
      "\tval loss: 0.25 | accuracy: 78.37\n",
      "epoch: 26\n",
      "\ttrain loss: 0.25 | accuracy: 77.25\n",
      "\tval loss: 0.25 | accuracy: 78.82\n",
      "epoch: 27\n",
      "\ttrain loss: 0.25 | accuracy: 77.71\n",
      "\tval loss: 0.25 | accuracy: 89.78\n",
      "epoch: 28\n",
      "\ttrain loss: 0.25 | accuracy: 88.03\n",
      "\tval loss: 0.26 | accuracy: 83.67\n",
      "epoch: 29\n",
      "\ttrain loss: 0.25 | accuracy: 88.61\n",
      "\tval loss: 0.24 | accuracy: 88.33\n",
      "epoch: 30\n",
      "\ttrain loss: 0.25 | accuracy: 88.30\n",
      "\tval loss: 0.24 | accuracy: 91.19\n",
      "epoch: 31\n",
      "\ttrain loss: 0.24 | accuracy: 89.44\n",
      "\tval loss: 0.24 | accuracy: 91.09\n",
      "epoch: 32\n",
      "\ttrain loss: 0.24 | accuracy: 89.58\n",
      "\tval loss: 0.24 | accuracy: 91.32\n",
      "epoch: 33\n",
      "\ttrain loss: 0.24 | accuracy: 89.60\n",
      "\tval loss: 0.23 | accuracy: 88.00\n",
      "epoch: 34\n",
      "\ttrain loss: 0.24 | accuracy: 89.67\n",
      "\tval loss: 0.24 | accuracy: 92.74\n",
      "epoch: 35\n",
      "\ttrain loss: 0.23 | accuracy: 90.32\n",
      "\tval loss: 0.23 | accuracy: 88.40\n",
      "epoch: 36\n",
      "\ttrain loss: 0.24 | accuracy: 90.58\n",
      "\tval loss: 0.24 | accuracy: 94.25\n",
      "epoch: 37\n",
      "\ttrain loss: 0.24 | accuracy: 91.16\n",
      "\tval loss: 0.23 | accuracy: 93.73\n",
      "epoch: 38\n",
      "\ttrain loss: 0.24 | accuracy: 91.78\n",
      "\tval loss: 0.22 | accuracy: 92.27\n",
      "epoch: 39\n",
      "\ttrain loss: 0.23 | accuracy: 91.87\n",
      "\tval loss: 0.23 | accuracy: 93.66\n",
      "epoch: 40\n",
      "\ttrain loss: 0.23 | accuracy: 91.51\n",
      "\tval loss: 0.22 | accuracy: 92.86\n",
      "epoch: 41\n",
      "\ttrain loss: 0.23 | accuracy: 91.56\n",
      "\tval loss: 0.22 | accuracy: 91.52\n",
      "epoch: 42\n",
      "\ttrain loss: 0.23 | accuracy: 91.85\n",
      "\tval loss: 0.22 | accuracy: 90.20\n",
      "epoch: 43\n",
      "\ttrain loss: 0.23 | accuracy: 92.03\n",
      "\tval loss: 0.22 | accuracy: 90.71\n",
      "epoch: 44\n",
      "\ttrain loss: 0.22 | accuracy: 92.23\n",
      "\tval loss: 0.22 | accuracy: 94.09\n",
      "epoch: 45\n",
      "\ttrain loss: 0.22 | accuracy: 92.30\n",
      "\tval loss: 0.22 | accuracy: 94.64\n",
      "epoch: 46\n",
      "\ttrain loss: 0.22 | accuracy: 92.35\n",
      "\tval loss: 0.21 | accuracy: 92.05\n",
      "epoch: 47\n",
      "\ttrain loss: 0.22 | accuracy: 92.61\n",
      "\tval loss: 0.21 | accuracy: 94.01\n",
      "epoch: 48\n",
      "\ttrain loss: 0.22 | accuracy: 93.08\n",
      "\tval loss: 0.21 | accuracy: 92.79\n",
      "epoch: 49\n",
      "\ttrain loss: 0.22 | accuracy: 92.89\n",
      "\tval loss: 0.21 | accuracy: 93.87\n",
      "epoch: 50\n",
      "\ttrain loss: 0.22 | accuracy: 93.16\n",
      "\tval loss: 0.22 | accuracy: 89.85\n",
      "epoch: 51\n",
      "\ttrain loss: 0.22 | accuracy: 93.08\n",
      "\tval loss: 0.22 | accuracy: 89.67\n",
      "epoch: 52\n",
      "\ttrain loss: 0.22 | accuracy: 93.25\n",
      "\tval loss: 0.21 | accuracy: 91.03\n",
      "epoch: 53\n",
      "\ttrain loss: 0.22 | accuracy: 93.26\n",
      "\tval loss: 0.22 | accuracy: 96.44\n",
      "epoch: 54\n",
      "\ttrain loss: 0.22 | accuracy: 93.86\n",
      "\tval loss: 0.21 | accuracy: 94.87\n",
      "epoch: 55\n",
      "\ttrain loss: 0.21 | accuracy: 93.93\n",
      "\tval loss: 0.21 | accuracy: 93.50\n",
      "epoch: 56\n",
      "\ttrain loss: 0.22 | accuracy: 93.60\n",
      "\tval loss: 0.21 | accuracy: 94.92\n",
      "epoch: 57\n",
      "\ttrain loss: 0.22 | accuracy: 94.35\n",
      "\tval loss: 0.21 | accuracy: 91.81\n",
      "epoch: 58\n",
      "\ttrain loss: 0.22 | accuracy: 94.12\n",
      "\tval loss: 0.20 | accuracy: 94.37\n",
      "epoch: 59\n",
      "\ttrain loss: 0.22 | accuracy: 94.09\n",
      "\tval loss: 0.22 | accuracy: 96.50\n",
      "epoch: 60\n",
      "\ttrain loss: 0.22 | accuracy: 94.15\n",
      "\tval loss: 0.21 | accuracy: 95.53\n",
      "epoch: 61\n",
      "\ttrain loss: 0.21 | accuracy: 94.34\n",
      "\tval loss: 0.20 | accuracy: 92.42\n",
      "epoch: 62\n",
      "\ttrain loss: 0.21 | accuracy: 93.99\n",
      "\tval loss: 0.20 | accuracy: 95.20\n",
      "epoch: 63\n",
      "\ttrain loss: 0.21 | accuracy: 94.14\n",
      "\tval loss: 0.20 | accuracy: 95.93\n",
      "epoch: 64\n",
      "\ttrain loss: 0.21 | accuracy: 94.35\n",
      "\tval loss: 0.20 | accuracy: 95.25\n",
      "epoch: 65\n",
      "\ttrain loss: 0.21 | accuracy: 94.40\n",
      "\tval loss: 0.20 | accuracy: 93.89\n",
      "epoch: 66\n",
      "\ttrain loss: 0.21 | accuracy: 94.53\n",
      "\tval loss: 0.20 | accuracy: 96.01\n",
      "epoch: 67\n",
      "\ttrain loss: 0.21 | accuracy: 94.84\n",
      "\tval loss: 0.21 | accuracy: 96.64\n",
      "epoch: 68\n",
      "\ttrain loss: 0.21 | accuracy: 94.29\n",
      "\tval loss: 0.20 | accuracy: 96.15\n",
      "epoch: 69\n",
      "\ttrain loss: 0.20 | accuracy: 94.86\n",
      "\tval loss: 0.20 | accuracy: 93.77\n",
      "epoch: 70\n",
      "\ttrain loss: 0.21 | accuracy: 94.77\n",
      "\tval loss: 0.20 | accuracy: 96.51\n",
      "epoch: 71\n",
      "\ttrain loss: 0.21 | accuracy: 94.76\n",
      "\tval loss: 0.20 | accuracy: 96.45\n",
      "epoch: 72\n",
      "\ttrain loss: 0.21 | accuracy: 94.97\n",
      "\tval loss: 0.20 | accuracy: 96.63\n",
      "epoch: 73\n",
      "\ttrain loss: 0.20 | accuracy: 95.10\n",
      "\tval loss: 0.20 | accuracy: 96.82\n",
      "epoch: 74\n",
      "\ttrain loss: 0.21 | accuracy: 95.17\n",
      "\tval loss: 0.20 | accuracy: 95.42\n",
      "epoch: 75\n",
      "\ttrain loss: 0.20 | accuracy: 95.22\n",
      "\tval loss: 0.20 | accuracy: 95.24\n",
      "epoch: 76\n",
      "\ttrain loss: 0.20 | accuracy: 94.93\n",
      "\tval loss: 0.20 | accuracy: 96.48\n",
      "epoch: 77\n",
      "\ttrain loss: 0.20 | accuracy: 95.21\n",
      "\tval loss: 0.20 | accuracy: 96.96\n",
      "epoch: 78\n",
      "\ttrain loss: 0.21 | accuracy: 95.04\n",
      "\tval loss: 0.21 | accuracy: 96.84\n",
      "epoch: 79\n",
      "\ttrain loss: 0.21 | accuracy: 95.60\n",
      "\tval loss: 0.19 | accuracy: 95.66\n",
      "epoch: 80\n",
      "\ttrain loss: 0.20 | accuracy: 95.36\n",
      "\tval loss: 0.19 | accuracy: 94.70\n",
      "epoch: 81\n",
      "\ttrain loss: 0.20 | accuracy: 95.17\n",
      "\tval loss: 0.19 | accuracy: 95.65\n",
      "epoch: 82\n",
      "\ttrain loss: 0.20 | accuracy: 95.51\n",
      "\tval loss: 0.20 | accuracy: 96.88\n",
      "epoch: 83\n",
      "\ttrain loss: 0.20 | accuracy: 95.57\n",
      "\tval loss: 0.20 | accuracy: 96.62\n",
      "epoch: 84\n",
      "\ttrain loss: 0.20 | accuracy: 95.38\n",
      "\tval loss: 0.19 | accuracy: 95.09\n",
      "epoch: 85\n",
      "\ttrain loss: 0.20 | accuracy: 95.65\n",
      "\tval loss: 0.20 | accuracy: 93.90\n",
      "epoch: 86\n",
      "\ttrain loss: 0.20 | accuracy: 95.79\n",
      "\tval loss: 0.19 | accuracy: 94.55\n",
      "epoch: 87\n",
      "\ttrain loss: 0.20 | accuracy: 95.50\n",
      "\tval loss: 0.19 | accuracy: 96.92\n",
      "epoch: 88\n",
      "\ttrain loss: 0.20 | accuracy: 95.82\n",
      "\tval loss: 0.20 | accuracy: 97.12\n",
      "epoch: 89\n",
      "\ttrain loss: 0.20 | accuracy: 95.65\n",
      "\tval loss: 0.20 | accuracy: 97.05\n",
      "epoch: 90\n",
      "\ttrain loss: 0.20 | accuracy: 96.01\n",
      "\tval loss: 0.19 | accuracy: 95.18\n",
      "epoch: 91\n",
      "\ttrain loss: 0.19 | accuracy: 95.83\n",
      "\tval loss: 0.19 | accuracy: 96.86\n",
      "epoch: 92\n",
      "\ttrain loss: 0.19 | accuracy: 95.82\n",
      "\tval loss: 0.19 | accuracy: 95.75\n",
      "epoch: 93\n",
      "\ttrain loss: 0.19 | accuracy: 95.66\n",
      "\tval loss: 0.19 | accuracy: 96.81\n",
      "epoch: 94\n",
      "\ttrain loss: 0.20 | accuracy: 95.81\n",
      "\tval loss: 0.21 | accuracy: 97.39\n",
      "epoch: 95\n",
      "\ttrain loss: 0.20 | accuracy: 96.15\n",
      "\tval loss: 0.19 | accuracy: 96.80\n",
      "epoch: 96\n",
      "\ttrain loss: 0.19 | accuracy: 96.24\n",
      "\tval loss: 0.19 | accuracy: 95.89\n",
      "epoch: 97\n",
      "\ttrain loss: 0.19 | accuracy: 95.77\n",
      "\tval loss: 0.19 | accuracy: 96.27\n",
      "epoch: 98\n",
      "\ttrain loss: 0.19 | accuracy: 96.20\n",
      "\tval loss: 0.19 | accuracy: 94.70\n",
      "epoch: 99\n",
      "\ttrain loss: 0.19 | accuracy: 96.25\n",
      "\tval loss: 0.19 | accuracy: 95.09\n",
      "epoch: 100\n",
      "\ttrain loss: 0.19 | accuracy: 96.16\n",
      "\tval loss: 0.19 | accuracy: 97.39\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_loss_v = 0\n",
    "    running_acc = 0\n",
    "    running_acc_v = 0\n",
    "    \n",
    "    dataset.set_split(\"train\")\n",
    "    data_gen = DataLoader(dataset, batch_size=1024, shuffle=True)\n",
    "    model.train()\n",
    "    for batch_index, (x, y) in enumerate(data_gen, 1):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        out_logit = model(x)\n",
    "        out = torch.sigmoid(out_logit)\n",
    "        \n",
    "        loss = criterion(out, y)\n",
    "        loss_train = loss.item()\n",
    "        running_loss += (loss_train - running_loss) / batch_index\n",
    "        \n",
    "        accuracy = compute_accuracy(y, out)\n",
    "        running_acc += (accuracy - running_acc) / batch_index\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    dataset.set_split(\"test\")\n",
    "    data_gen = DataLoader(dataset, batch_size=1024)\n",
    "    model.eval()\n",
    "    for batch_index, (x, y) in enumerate(data_gen, 1):\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = model(x)\n",
    "            out = torch.sigmoid(out)\n",
    "        \n",
    "        loss = criterion(out, y)\n",
    "        loss_val = loss.item()\n",
    "        running_loss_v += (loss_val - running_loss_v) / batch_index\n",
    "        \n",
    "        accuracy = compute_accuracy(y, out)\n",
    "        running_acc_v += (accuracy - running_acc_v) / batch_index\n",
    "    \n",
    "    print(f'epoch: {epoch}')\n",
    "    print(f'\\ttrain loss: {running_loss:.2f} | accuracy: {running_acc:.2f}')\n",
    "    print(f'\\tval loss: {running_loss_v:.2f} | accuracy: {running_acc_v:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
