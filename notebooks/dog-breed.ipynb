{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/dog-breed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(data_path, 'train')\n",
    "test_path = os.path.join(data_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_table = pd.read_csv(os.path.join(data_path, \"labels.csv\"))\n",
    "samp = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10222, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2idx = dict((label, idx) for idx, label in enumerate(label_table.breed.unique()))\n",
    "idx2label = dict((idx, label) for idx, label in enumerate(label_table.breed.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_table[\"breed_id\"] = label_table.breed.map(label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, freq = np.unique(label_table.breed_id.values, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(label, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 7, figsize=(15, 6))\n",
    "r = 0\n",
    "c = 0\n",
    "for idx in label_table.index[:21]:\n",
    "    img = plt.imread(os.path.join(train_path, label_table.loc[idx, \"id\"] + \".jpg\"))\n",
    "    \n",
    "    ax[r, c].imshow(img)\n",
    "    ax[r, c].axis(\"off\")\n",
    "    ax[r, c].set_title(label_table.loc[idx, \"breed\"])\n",
    "    \n",
    "    c += 1\n",
    "    if c % 7 == 0:\n",
    "        c = 0 \n",
    "        r += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = {\"path\": [], \"h\": [], \"w\": [], \"c\": []}\n",
    "for idx in tqdm(label_table.index):\n",
    "    img = plt.imread(os.path.join(train_path, label_table.loc[idx, \"id\"] + \".jpg\"))\n",
    "    h, w, c = img.shape\n",
    "    img_dim[\"path\"].append(label_table.loc[idx, \"id\"])\n",
    "    img_dim[\"h\"].append(h)\n",
    "    img_dim[\"w\"].append(w)\n",
    "    img_dim[\"c\"].append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_img_dim = pd.DataFrame(img_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_img_dim.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(img_dim[\"h\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(img_dim[\"w\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_scaling(h, w):\n",
    "    max_pxl = 300\n",
    "    \n",
    "    if h > w:\n",
    "        ratio = max_pxl / h\n",
    "    else:\n",
    "        ratio = max_pxl / w\n",
    "    \n",
    "    new_height = h * ratio\n",
    "    new_width = w * ratio\n",
    "        \n",
    "    return  new_height, new_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in d_img_dim.index[:5]:\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    img = plt.imread(os.path.join(train_path, label_table.loc[idx, \"id\"] + \".jpg\"))\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title(str(img.shape))\n",
    "    \n",
    "    h, w, _ = img.shape\n",
    "    \n",
    "    h_new, w_new = img_scaling(h, w)\n",
    "    img_re = cv2.resize(img, (int(w_new), int(h_new)))\n",
    "    ax[1].imshow(img_re)\n",
    "    ax[1].set_title(str(img_re.shape))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_table[\"id\"] = label_table.id.apply(lambda x: os.path.join(train_path, x + \".jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(label_table.id.values, label_table.breed_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreedDataset(Dataset):\n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        self.dataset = {\n",
    "            \"train\": (X_train, y_train, len(X_train)),\n",
    "            \"test\": (X_test, y_test, len(X_test))\n",
    "        }\n",
    "        self.set_split(\"train\")\n",
    "        \n",
    "    def set_split(self, split=\"train\"):\n",
    "        self.x, self.target, self.length = self.dataset[split]\n",
    "    \n",
    "    def img_scaling(self, img):\n",
    "        max_pxl = 300\n",
    "        h, w, c = img.shape\n",
    "        if h > w:\n",
    "            ratio = max_pxl / h\n",
    "        else:\n",
    "            ratio = max_pxl / w\n",
    "\n",
    "        new_height = h * ratio\n",
    "        new_width = w * ratio\n",
    "        \n",
    "        img_re = cv2.resize(img, (int(new_width), int(new_height)))\n",
    "        \n",
    "        return  img_re\n",
    "    \n",
    "    def padding(self, img_arr):\n",
    "        x = np.zeros((300, 300, 3))\n",
    "        h, w, c = img_arr.shape\n",
    "        x[:h,:w,:] = img_arr\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def read_image(self, path):\n",
    "        img = plt.imread(path, 0)\n",
    "        img = img / 255\n",
    "        img = self.img_scaling(img)\n",
    "        img = self.padding(img)\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        return img\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        x = self.read_image(x)\n",
    "        x = torch.Tensor(x)\n",
    "        \n",
    "        y = torch.LongTensor([self.target[index]])\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 3, kernel_size = 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 3, kernel_size = 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 3, kernel_size = 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 1, kernel_size = 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(4761, 512)\n",
    "        self.fc2 = nn.Linear(512, 120)\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        out = self.network(input_)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BreedDataset(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_param = sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of parameters 2,500,464\n"
     ]
    }
   ],
   "source": [
    "print(f\"total number of parameters {num_param:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(out, y):\n",
    "    out = sm(out)\n",
    "    n_indicies = out.argmax(1).long()\n",
    "    n_correct = torch.eq(n_indicies, y).sum().item()\n",
    "    accuracy = (n_correct / y.shape[0]) * 100\n",
    "    \n",
    "    return accuracy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_duration(start, end):\n",
    "    duration = end - start\n",
    "    m = int(duration / 60)\n",
    "    s = int(duration % 60)\n",
    "    \n",
    "    return m, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = {\n",
    "    \"running_loss\": [],\n",
    "    \"running_loss_v\": [],\n",
    "    \"running_acc\": [],\n",
    "    \"running_acc_v\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | 2 m 32 s\n",
      "\ttrain loss 4.79 | accuracy: 1.13\n",
      "\tval loss 4.79 | accuracy: 0.69\n",
      "epoch: 2 | 2 m 45 s\n",
      "\ttrain loss 4.78 | accuracy: 1.15\n",
      "\tval loss 4.78 | accuracy: 1.06\n",
      "epoch: 3 | 3 m 7 s\n",
      "\ttrain loss 4.78 | accuracy: 1.28\n",
      "\tval loss 4.79 | accuracy: 1.06\n",
      "epoch: 4 | 3 m 5 s\n",
      "\ttrain loss 4.78 | accuracy: 1.28\n",
      "\tval loss 4.79 | accuracy: 1.06\n",
      "epoch: 5 | 3 m 8 s\n",
      "\ttrain loss 4.78 | accuracy: 1.28\n",
      "\tval loss 4.79 | accuracy: 1.06\n",
      "epoch: 6 | 3 m 6 s\n",
      "\ttrain loss 4.78 | accuracy: 1.28\n",
      "\tval loss 4.79 | accuracy: 1.06\n",
      "epoch: 7 | 3 m 9 s\n",
      "\ttrain loss 4.78 | accuracy: 1.28\n",
      "\tval loss 4.79 | accuracy: 1.06\n",
      "epoch: 8 | 3 m 10 s\n",
      "\ttrain loss 4.78 | accuracy: 1.28\n",
      "\tval loss 4.79 | accuracy: 1.06\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    running_loss = 0\n",
    "    running_loss_v = 0\n",
    "    running_acc = 0\n",
    "    running_acc_v = 0\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    dataset.set_split(\"train\")\n",
    "    data_gen = DataLoader(dataset, batch_size = 384)\n",
    "    model.train()\n",
    "    for batch_index, (x, y) in enumerate(data_gen, 1):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.squeeze(1)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        out = model(x)\n",
    "        \n",
    "        loss = criterion(out, y)\n",
    "        loss_ = loss.item()\n",
    "        running_loss += (loss_ - running_loss) / batch_index\n",
    "        \n",
    "        accuracy = compute_accuracy(out, y)\n",
    "        running_acc += (accuracy - running_acc) / batch_index\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    dataset.set_split(\"test\")\n",
    "    data_gen = DataLoader(dataset, batch_size = 384)\n",
    "    model.eval()\n",
    "    for batch_index, (x, y) in enumerate(data_gen, 1):\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.squeeze(1)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        out = model(x)\n",
    "        \n",
    "        loss = criterion(out, y)\n",
    "        loss_ = loss.item()\n",
    "        running_loss_v += (loss_ - running_loss_v) / batch_index\n",
    "        \n",
    "        accuracy = compute_accuracy(out, y)\n",
    "        running_acc_v += (accuracy - running_acc_v) / batch_index\n",
    "        \n",
    "    end = time.perf_counter()\n",
    "    m, s = compute_duration(start, end)\n",
    "    print(f\"epoch: {epoch} | {m} m {s} s\")\n",
    "    print(f\"\\ttrain loss {running_loss:.2f} | accuracy: {running_acc:.2f}\")\n",
    "    print(f\"\\tval loss {running_loss_v:.2f} | accuracy: {running_acc_v:.2f}\")\n",
    "    \n",
    "    history_dict[\"running_loss\"].append(running_loss)\n",
    "    history_dict[\"running_loss_v\"].append(running_loss_v)\n",
    "    history_dict[\"running_acc\"].append(running_acc)\n",
    "    history_dict[\"running_acc_v\"].append(running_acc_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
