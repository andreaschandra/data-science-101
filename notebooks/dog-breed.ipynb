{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/dog-breed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(data_path, 'train')\n",
    "test_path = os.path.join(data_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_table = pd.read_csv(os.path.join(data_path, \"labels.csv\"))\n",
    "samp = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2idx = dict((label, idx) for idx, label in enumerate(label_table.breed.unique()))\n",
    "idx2label = dict((idx, label) for idx, label in enumerate(label_table.breed.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_table[\"breed_id\"] = label_table.breed.map(label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label, freq = np.unique(label_table.breed_id.values, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 5))\n",
    "# plt.bar(label, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(3, 7, figsize=(15, 6))\n",
    "# r = 0\n",
    "# c = 0\n",
    "# for idx in label_table.index[:21]:\n",
    "#     img = plt.imread(os.path.join(train_path, label_table.loc[idx, \"id\"] + \".jpg\"))\n",
    "    \n",
    "#     ax[r, c].imshow(img)\n",
    "#     ax[r, c].axis(\"off\")\n",
    "#     ax[r, c].set_title(label_table.loc[idx, \"breed\"])\n",
    "    \n",
    "#     c += 1\n",
    "#     if c % 7 == 0:\n",
    "#         c = 0 \n",
    "#         r += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_dim = {\"path\": [], \"h\": [], \"w\": [], \"c\": []}\n",
    "# for idx in tqdm(label_table.index):\n",
    "#     img = plt.imread(os.path.join(train_path, label_table.loc[idx, \"id\"] + \".jpg\"))\n",
    "#     h, w, c = img.shape\n",
    "#     img_dim[\"path\"].append(label_table.loc[idx, \"id\"])\n",
    "#     img_dim[\"h\"].append(h)\n",
    "#     img_dim[\"w\"].append(w)\n",
    "#     img_dim[\"c\"].append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_img_dim = pd.DataFrame(img_dim)\n",
    "\n",
    "# d_img_dim.describe()\n",
    "\n",
    "# sns.boxplot(img_dim[\"h\"])\n",
    "\n",
    "# sns.boxplot(img_dim[\"w\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def img_scaling(h, w):\n",
    "#     max_pxl = 300\n",
    "    \n",
    "#     if h > w:\n",
    "#         ratio = max_pxl / h\n",
    "#     else:\n",
    "#         ratio = max_pxl / w\n",
    "    \n",
    "#     new_height = h * ratio\n",
    "#     new_width = w * ratio\n",
    "        \n",
    "#     return  new_height, new_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in d_img_dim.index[:5]:\n",
    "#     fig, ax = plt.subplots(1, 2)\n",
    "#     img = plt.imread(os.path.join(train_path, label_table.loc[idx, \"id\"] + \".jpg\"))\n",
    "#     ax[0].imshow(img)\n",
    "#     ax[0].set_title(str(img.shape))\n",
    "    \n",
    "#     h, w, _ = img.shape\n",
    "    \n",
    "#     h_new, w_new = img_scaling(h, w)\n",
    "#     img_re = cv2.resize(img, (int(w_new), int(h_new)))\n",
    "#     ax[1].imshow(img_re)\n",
    "#     ax[1].set_title(str(img_re.shape))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_table[\"id\"] = label_table.id.apply(lambda x: os.path.join(train_path, x + \".jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(label_table.id.values, label_table.breed_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreedDataset(Dataset):\n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        self.dataset = {\n",
    "            \"train\": (X_train, y_train, len(X_train)),\n",
    "            \"test\": (X_test, y_test, len(X_test))\n",
    "        }\n",
    "        self.set_split(\"train\")\n",
    "        \n",
    "    def set_split(self, split=\"train\"):\n",
    "        self.x, self.target, self.length = self.dataset[split]\n",
    "    \n",
    "    def img_scaling(self, img):\n",
    "        max_pxl = 300\n",
    "        h, w, c = img.shape\n",
    "        if h > w:\n",
    "            ratio = max_pxl / h\n",
    "        else:\n",
    "            ratio = max_pxl / w\n",
    "\n",
    "        new_height = h * ratio\n",
    "        new_width = w * ratio\n",
    "        \n",
    "        img_re = cv2.resize(img, (int(new_width), int(new_height)))\n",
    "        \n",
    "        return  img_re\n",
    "    \n",
    "    def padding(self, img_arr):\n",
    "        x = np.zeros((300, 300, 3))\n",
    "        h, w, c = img_arr.shape\n",
    "        x[:h,:w,:] = img_arr\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def read_image(self, path):\n",
    "        img = plt.imread(path, 0)\n",
    "        img = img / 255\n",
    "        img = self.img_scaling(img)\n",
    "        img = self.padding(img)\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        return img\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        x = self.read_image(x)\n",
    "        x = torch.Tensor(x)\n",
    "        \n",
    "        y = torch.LongTensor([self.target[index]])\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 1, kernel_size = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 1, kernel_size = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 1, kernel_size = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(5041, 512)\n",
    "        self.fc2 = nn.Linear(512, 120)\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        out = self.network(input_)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BreedDataset(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Classifier().to(device)\n",
    "model = torchvision.models.inception_v3(pretrained=True, progress=True, aux_logits = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(2048, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_param = sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"total number of parameters {num_param:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(out, y):\n",
    "    out = sm(out)\n",
    "    n_indicies = out.argmax(1).long()\n",
    "    n_correct = torch.eq(n_indicies, y).sum().item()\n",
    "    accuracy = (n_correct / y.shape[0]) * 100\n",
    "    \n",
    "    return accuracy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_duration(start, end):\n",
    "    duration = end - start\n",
    "    m = int(duration / 60)\n",
    "    s = int(duration % 60)\n",
    "    \n",
    "    return m, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = {\n",
    "    \"running_loss\": [],\n",
    "    \"running_loss_v\": [],\n",
    "    \"running_acc\": [],\n",
    "    \"running_acc_v\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "epochs = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs):\n",
    "    running_loss = 0\n",
    "    running_loss_v = 0\n",
    "    running_acc = 0\n",
    "    running_acc_v = 0\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    dataset.set_split(\"train\")\n",
    "    data_gen = DataLoader(dataset, batch_size = batchsize)\n",
    "    model.train()\n",
    "    for batch_index, (x, y) in enumerate(data_gen, 1):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.squeeze(1)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        out = model(x)\n",
    "        \n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        loss_ = loss.item()\n",
    "        running_loss += (loss_ - running_loss) / batch_index\n",
    "        \n",
    "        accuracy = compute_accuracy(out, y)\n",
    "        running_acc += (accuracy - running_acc) / batch_index\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    dataset.set_split(\"test\")\n",
    "    data_gen = DataLoader(dataset, batch_size = batchsize)\n",
    "    model.eval()\n",
    "    for batch_index, (x, y) in enumerate(data_gen, 1):\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.squeeze(1)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        out = model(x)\n",
    "        \n",
    "        loss = criterion(out, y)\n",
    "        loss_ = loss.item()\n",
    "        running_loss_v += (loss_ - running_loss_v) / batch_index\n",
    "        \n",
    "        accuracy = compute_accuracy(out, y)\n",
    "        running_acc_v += (accuracy - running_acc_v) / batch_index\n",
    "        \n",
    "    end = time.perf_counter()\n",
    "    m, s = compute_duration(start, end)\n",
    "    print(f\"epoch: {epoch} | {m} m {s} s\")\n",
    "    print(f\"\\ttrain loss {running_loss:.2f} | accuracy: {running_acc:.2f}\")\n",
    "    print(f\"\\tval loss {running_loss_v:.2f} | accuracy: {running_acc_v:.2f}\")\n",
    "    \n",
    "    history_dict[\"running_loss\"].append(running_loss)\n",
    "    history_dict[\"running_loss_v\"].append(running_loss_v)\n",
    "    history_dict[\"running_acc\"].append(running_acc)\n",
    "    history_dict[\"running_acc_v\"].append(running_acc_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(history_dict, open(\"history_dog_inception_v3.pkl\", \"wb\"))\n",
    "torch.save((model.state_dict(), \"model_dog_inception_v3.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
